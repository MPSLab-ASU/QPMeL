Quantum Machine Learning (QML) promises richer representations and improved learning by leveraging the unique properties of quantum computation. A necessary first step in using QML is to encode classical data into quantum states. Static encoding mechanisms offer limited expressivity, while quantum training suffers from barren plateaus, making optimization unstable and inefficient. We propose Quantum Projective Metric Learning (QPMeL) - a quantum-aware, classically-trained method to learn dense and high-quality quantum encodings. QPMeL achieves this by mapping classical data to the surface of independent unit spheres in $\mathbb{R}^3$, which naturally aligns with the state of multiple unentangled qubits. QPMeL also introduces a novel Projective Metric Function (PMeF) to approximate Hilbert space similarity in $\mathbb{R}^3$ and a gradient stabilization trick further enhances training efficiency. QPMeL achieves state-of-the-art performance on MNIST, Fashion-MNIST, and Omniglot, scaling up to 10-class classification and 15-way few-shot learning with high accuracy using significantly fewer qubits. It is also the first QML approach to support multi-modal (image-text) learning, achieving over 90\% accuracy in the 15-way-1-shot setting with just 20 qubits.